{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lec26.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP0lkd-l6ZqH",
        "colab_type": "text"
      },
      "source": [
        "# Jupyter Notebook\n",
        "\n",
        "This is a Jupyter Notebook, which is a basically just a super fancy Python shell.\n",
        "\n",
        "You may have \"cells\" that can either be text (like this one) or executable Python code. Notebooks are really nice because they allow you to rapidly develop Python code by writing small bits of code, testing their output, and moving on to the next bit; this interactive nature of the notebook is a huge plus to professional Python developers. \n",
        "\n",
        "It's also nice, because it's really easy to share your code with others and surround it with text to tell a story! \n",
        "\n",
        "# Colaboratory\n",
        "Colaboratory is a service provided by Google to take a Jupyter Notebook (a standard formay of a `.ipynb` file) and let users edit/run the code in the notebook for free! \n",
        "\n",
        "This notebook is write-protected so you are not able to edit the  notebook that the whole class will look at, but you are able to open up the notebook in \"playground mode\" which lets you make edits to a temporary copy of the notebook. If you want to save the changes you made to this notebook, you will have to follow the instructions when you try to save to copy the notebook to your Google Drive. \n",
        "\n",
        "# Setup\n",
        "Make sure you run the following cell(s) before trying to run any the following cells. You do not need to understand what they are doing, it's just a way to make sure there is a file we want to use stored on the computer running this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIXl9KBOxVKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def save_file(url, file_name):\n",
        "  r = requests.get(url)\n",
        "  with open(file_name, 'wb') as f:\n",
        "    f.write(r.content)\n",
        "\n",
        "save_file('https://courses.cs.washington.edu/courses/cse163/19sp/' +\n",
        "          'files/lectures/05-29/BostonHousing.csv', 'BostonHousing.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1Ub00hoE63",
        "colab_type": "text"
      },
      "source": [
        "# Functional programming\n",
        "For this problem, we want to multiply every number in a list2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2DNcHhrdgwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nums = [1, 5, 7, 10, 14, 27]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUiN5BrEoGhS",
        "colab_type": "text"
      },
      "source": [
        "We have seen before in class that we can solve this with a simple for loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oDrFzOSdgtk",
        "colab_type": "code",
        "outputId": "fbff0957-74a1-4e43-f8aa-b7f928191ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "two_nums = []\n",
        "for num in nums:\n",
        "  two_nums.append(2 * num)\n",
        "print(two_nums)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 10, 14, 20, 28, 54]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_DBbWd4oNW4",
        "colab_type": "text"
      },
      "source": [
        "You might also remember we can use a **list comprehension** to abstract away building up the new list explicitly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLQhcObydgpt",
        "colab_type": "code",
        "outputId": "701f927d-daa2-43ed-8893-b0e27e19d2ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[2 * num for num in nums]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 10, 14, 20, 28, 54]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R5XzXhvoSjj",
        "colab_type": "text"
      },
      "source": [
        "While this appraoch is a bit easier to read, it still requires us to write out an explicit loop. In **functional programming**, we prefer to not have to write \"how\" to do something but focus more on the \"what\". \n",
        "\n",
        "In Python, we use the `map` function to apply a given function over a list of values. The `map` function is \"lazy\" in the sense it won't compute all the values unless we ask for them. To do this, we pass it to the `list` constructor so it evaluates all the elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQk90wyMdggm",
        "colab_type": "code",
        "outputId": "465a3d4a-1eaf-4cb7-a882-ba446af8abf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def times_two(num):\n",
        "  return 2 * num\n",
        "\n",
        "list(map(times_two, nums))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 10, 14, 20, 28, 54]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1Tl8klQolwG",
        "colab_type": "text"
      },
      "source": [
        "We could go ahead and write our own `our_map` function to show exactly how `map` is implemented (minus the lazy evaluation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp3XFdbEmaQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def our_map(f, vals):\n",
        "  return [f(v) for v in vals]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Qkao3om-iG",
        "colab_type": "code",
        "outputId": "3571e036-11a5-46e0-a4f3-bf37ab28168d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "our_map(times_two, nums)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 10, 14, 20, 28, 54]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvYH1hbLosBw",
        "colab_type": "text"
      },
      "source": [
        "It is also good to remind you that we can use the lambda syntax to define an **anonymous function** so we don't have to go write a named function like `times_two` every single time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5oq1O9DnAQ7",
        "colab_type": "code",
        "outputId": "83248e2a-e4ee-453a-9835-a19f8b45ce9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(map(lambda num: 2 * num, nums))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 10, 14, 20, 28, 54]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_CK3n6Fozi9",
        "colab_type": "text"
      },
      "source": [
        "We then went on to your next higher-order function **filter**. This is similar to the structure of `map`, but instead of returning new values the function passed should return `bool`s. `filter` will keep all values the function returns true for"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3w8f-GLnWF6",
        "colab_type": "code",
        "outputId": "66534cce-2c21-49b6-82cb-b2e13ca5a19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(filter(lambda num: num % 2 == 0, nums))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 14]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBQ-soq_o9q6",
        "colab_type": "text"
      },
      "source": [
        "Reduce was actually removed as a built-in function from Python in version 3.0. If we want to use `reduce`, we have to import it from `functools`.\n",
        "\n",
        "The function passed to `reduce` takes 2 values, the first is the current accumalation of the previous values and the second is the next file; the function shows how the combine the next value with all the previous ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2RzU_U7neYN",
        "colab_type": "code",
        "outputId": "09dc4dab-835c-4b58-90ba-4bfbf04d4c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from functools import reduce\n",
        "reduce(lambda cumulative, curr: cumulative + curr, nums)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuDbH0qvpTAW",
        "colab_type": "text"
      },
      "source": [
        "The example above computes the sum of all the numbers. It might be clearer too see one way that we could implement `reduce`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hPMVX83pZG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def our_reduce(f, vals):\n",
        "  acc = vals[0]\n",
        "  for v in vals[1:]:\n",
        "    acc = f(acc, v)\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIhBpy-Apm23",
        "colab_type": "text"
      },
      "source": [
        "# Spark\n",
        "We saw in lecture this framework called Spark let's us easily write code that runs on a distributed system. Below we have an example that trains a machine learning model to predict housing prices. Notice that the API is very different than `sklearn`, but there are a lot of the same components. \n",
        "\n",
        "This example is a bit lame in some sense because it is running locally (on this one Google machine) and not on a distributed system, but the cool thing is this code will run on a distributed system with minor modification! That is the nice thing about using the Spark API in this case.\n",
        "\n",
        "We will explain what each cell is trying to do, but we cannot explain every single line without writing a huge chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYRLWqWkqhNE",
        "colab_type": "text"
      },
      "source": [
        "This cell is installing all the necessary tools to run Spark (Java, Spark, `findspark` python program)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INn5uHVAqAhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbFHxqXYqpDk",
        "colab_type": "text"
      },
      "source": [
        "The next cell is setting some \"environment variables\" so that the program knows where to find the required files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OPf90vwqonX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.3-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yhqWo3RqwBj",
        "colab_type": "text"
      },
      "source": [
        "`findspark` is the library that lets us use Spark in Python. The `spark` variable is what we will use to talk to the Spark server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU_XwSFwqwRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "# This is the line that lets us connect to a remote server cluster\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF4T2DeFrAEU",
        "colab_type": "text"
      },
      "source": [
        "The following cell reads the Boston housing dataset into a Spark data structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwq9VFJCrAmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = spark.read.csv('BostonHousing.csv', inferSchema=True, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTZM4DEk2QMR",
        "colab_type": "text"
      },
      "source": [
        "The `dataset` variable has a method to let us see the columns and their types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AXKLiQH2Gcj",
        "colab_type": "code",
        "outputId": "89df0650-fbe1-4660-f9ea-cc5ad6490f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "dataset.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- crim: double (nullable = true)\n",
            " |-- zn: double (nullable = true)\n",
            " |-- indus: double (nullable = true)\n",
            " |-- chas: integer (nullable = true)\n",
            " |-- nox: double (nullable = true)\n",
            " |-- rm: double (nullable = true)\n",
            " |-- age: double (nullable = true)\n",
            " |-- dis: double (nullable = true)\n",
            " |-- rad: integer (nullable = true)\n",
            " |-- tax: integer (nullable = true)\n",
            " |-- ptratio: double (nullable = true)\n",
            " |-- b: double (nullable = true)\n",
            " |-- lstat: double (nullable = true)\n",
            " |-- medv: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgGi4AID2cDq",
        "colab_type": "text"
      },
      "source": [
        "The code in this cell sets up the training data so that we separate the features and the outputs. The list line shows us what this new dataset looks like.  The dataset has two columns, one that stores a vector of all the features for that row, and the other is label `medv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmXwfRKj2TTr",
        "colab_type": "code",
        "outputId": "4b63bce1-4e0a-451e-ac4f-cd032ee60dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Input all the features in one vector column\n",
        "assembler = VectorAssembler(inputCols=['crim', 'zn', 'indus', 'chas', 'nox', \n",
        "                                       'rm', 'age', 'dis', 'rad', 'tax', \n",
        "                                       'ptratio', 'b', 'lstat'], \n",
        "                            outputCol = 'Attributes')\n",
        "output = assembler.transform(dataset)\n",
        "\n",
        "# Input vs Output\n",
        "finalized_data = output.select('Attributes', 'medv')\n",
        "finalized_data.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+\n",
            "|          Attributes|medv|\n",
            "+--------------------+----+\n",
            "|[0.00632,18.0,2.3...|24.0|\n",
            "|[0.02731,0.0,7.07...|21.6|\n",
            "|[0.02729,0.0,7.07...|34.7|\n",
            "|[0.03237,0.0,2.18...|33.4|\n",
            "|[0.06905,0.0,2.18...|36.2|\n",
            "|[0.02985,0.0,2.18...|28.7|\n",
            "|[0.08829,12.5,7.8...|22.9|\n",
            "|[0.14455,12.5,7.8...|27.1|\n",
            "|[0.21124,12.5,7.8...|16.5|\n",
            "|[0.17004,12.5,7.8...|18.9|\n",
            "|[0.22489,12.5,7.8...|15.0|\n",
            "|[0.11747,12.5,7.8...|18.9|\n",
            "|[0.09378,12.5,7.8...|21.7|\n",
            "|[0.62976,0.0,8.14...|20.4|\n",
            "|[0.63796,0.0,8.14...|18.2|\n",
            "|[0.62739,0.0,8.14...|19.9|\n",
            "|[1.05393,0.0,8.14...|23.1|\n",
            "|[0.7842,0.0,8.14,...|17.5|\n",
            "|[0.80271,0.0,8.14...|20.2|\n",
            "|[0.7258,0.0,8.14,...|18.2|\n",
            "+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huSfiexE3GOk",
        "colab_type": "text"
      },
      "source": [
        "The cell below actually trains the model and prints its predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPUm9Wok2xq1",
        "colab_type": "code",
        "outputId": "b3131a66-f6b0-48f1-be73-33bd97db93d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "# Split training and testing data\n",
        "train_data,test_data = finalized_data.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Learn to fit the model from training set\n",
        "regressor = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv')\n",
        "regressor = regressor.fit(train_data)\n",
        "\n",
        "# To predict the prices on testing set\n",
        "pred = regressor.evaluate(test_data)\n",
        "pred.predictions.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+------------------+\n",
            "|          Attributes|medv|        prediction|\n",
            "+--------------------+----+------------------+\n",
            "|[0.00906,90.0,2.9...|32.2| 31.41528319800314|\n",
            "|[0.01311,90.0,1.2...|35.4|30.961419505594797|\n",
            "|[0.01381,80.0,0.4...|50.0| 40.68022853897539|\n",
            "|[0.01538,90.0,3.7...|44.0| 37.53039981560234|\n",
            "|[0.01951,17.5,1.3...|33.0| 22.91406322761884|\n",
            "|[0.02177,82.5,2.0...|42.3| 36.77392391351592|\n",
            "|[0.02763,75.0,2.9...|30.8|31.641561563069722|\n",
            "|[0.02875,28.0,15....|25.0| 29.41820794057692|\n",
            "|[0.02985,0.0,2.18...|28.7| 25.17682920723198|\n",
            "|[0.03113,0.0,4.39...|17.5| 16.10388162964486|\n",
            "|[0.03445,82.5,2.0...|24.1|29.162470316265285|\n",
            "|[0.03466,35.0,6.0...|19.4| 23.16534532152732|\n",
            "|[0.03502,80.0,4.9...|28.5| 33.87080772723026|\n",
            "|[0.03615,80.0,4.9...|27.9| 32.28690618950903|\n",
            "|[0.03659,25.0,4.8...|24.8| 26.14666933761385|\n",
            "|[0.03932,0.0,3.41...|22.0|27.673911925939606|\n",
            "|[0.04527,0.0,11.9...|20.6|23.010732689972585|\n",
            "|[0.0456,0.0,13.89...|23.3|26.843149181282804|\n",
            "|[0.0459,52.5,5.32...|22.3| 26.98467305880051|\n",
            "|[0.04741,0.0,11.9...|11.9|22.953119173616564|\n",
            "+--------------------+----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXcGI8ku3MPM",
        "colab_type": "text"
      },
      "source": [
        "The model we are using is called **linear regresssion** which tries to fit a \"line\" through the dataset to predict the value. We put line in quotes because in higher dimensions, its actually a hyper-plane. With linear regression, we can look at the coefficients for each feature and the intercept of the line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPnRNbPi29qu",
        "colab_type": "code",
        "outputId": "ab5f4d09-7f0b-42bf-d706-2c46d2a70f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# coefficient of the regression model\n",
        "coeff = regressor.coefficients\n",
        "print(f'The coefficient of the model is : {coeff}')\n",
        "\n",
        "# Y intercept\n",
        "intr = regressor.intercept\n",
        "print (f'The Intercept of the model is : {intr}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The coefficient of the model is : [-0.10725558788839656,0.051397562790752235,0.025320444127234085,2.8069557086057144,-18.896903103025814,3.7332456339812734,0.002297829720421558,-1.6259291041305706,0.29383293785790826,-0.01352466376227244,-0.868844389251999,0.0089061537930031,-0.5190221632958711]\n",
            "The Intercept of the model is : 37.05904798202716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBXVcV793p0c",
        "colab_type": "text"
      },
      "source": [
        "The last step is to evaluate the model by looking at the test error. There are two metrics we will look at \n",
        "* The first is called Root Mean Square Error (RMSE) which measures the square root of the sum of the squared errors made by the model on each point (a lower RMSE is better). Mathematically, for our model $\\hat{f}$ on a dataset $X$ with labels $y$, the RMSE is \n",
        "\n",
        "$$RMSE(\\hat{f}, X, y) = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n \\left( y_i - \\hat{f}(X_i)\\right)^2}$$\n",
        "\n",
        "* The other metric used is the $R^2$ correlation coefficient, which is a common statistical measurement to identify the \"fit\" of the model. A value closer to 1 indicates a better fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBF5wDSk3dkG",
        "colab_type": "code",
        "outputId": "ef5deecf-cc86-4a52-f11c-b0975cd383b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "eval = RegressionEvaluator(labelCol='medv', \n",
        "                           predictionCol='prediction', \n",
        "                           metricName='rmse')\n",
        "\n",
        "# Root Mean Square Error\n",
        "rmse = eval.evaluate(pred.predictions)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "# r2 - coefficient of determination\n",
        "r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})\n",
        "print(f'r2: {r2}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 4.686977314624061\n",
            "r2: 0.7307918797596511\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}